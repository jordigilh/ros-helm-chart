"""
Deployment Validation Phase
============================

Validates deployment health beyond application-level tests.
Ensures infrastructure, integration, and operational readiness.
"""

from typing import Dict, List, Optional
import time


class DeploymentValidationPhase:
    """Comprehensive deployment validation"""

    def __init__(self, k8s_client, db_client):
        """Initialize deployment validator

        Args:
            k8s_client: KubernetesClient instance
            db_client: DatabaseClient instance
        """
        self.k8s = k8s_client
        self.db = db_client
        self.results = {
            'infrastructure': {},
            'integration': {},
            'data_flow': {},
            'performance': {},
            'operational': {}
        }

    # ========================================================================
    # Infrastructure Validation
    # ========================================================================

    def validate_pod_health(self) -> Dict[str, any]:
        """Validate all pods are healthy"""
        print("\nðŸ—ï¸  Infrastructure: Pod Health")

        health = self.k8s.get_pod_health()
        pods = self.k8s.get_pods()

        issues = []
        for pod in pods:
            # Check if running
            if pod.status.phase != "Running":
                issues.append(f"Pod {pod.metadata.name} not running: {pod.status.phase}")

            # Check if ready
            ready = any(c.type == "Ready" and c.status == "True"
                       for c in (pod.status.conditions or []))
            if not ready:
                issues.append(f"Pod {pod.metadata.name} not ready")

            # Check restarts
            for container in (pod.status.container_statuses or []):
                if container.restart_count > 5:
                    issues.append(
                        f"Pod {pod.metadata.name} container {container.name} "
                        f"has {container.restart_count} restarts"
                    )

        result = {
            'total_pods': health['total'],
            'running_pods': health['running'],
            'ready_pods': health['ready'],
            'issues': issues,
            'passed': len(issues) == 0 and health['ready'] >= 20
        }

        print(f"  Total: {result['total_pods']}, Ready: {result['ready_pods']}")
        if result['passed']:
            print("  âœ… All pods healthy")
        else:
            print(f"  âŒ {len(issues)} issues found")
            for issue in issues[:5]:
                print(f"    - {issue}")

        return result

    def validate_services(self) -> Dict[str, any]:
        """Validate services are accessible"""
        print("\nðŸŒ Infrastructure: Service Endpoints")

        required_services = [
            'koku-koku-api',
            'koku-koku-db',
            'redis',
        ]

        accessible = []
        inaccessible = []

        for svc_name in required_services:
            endpoint = self.k8s.get_service_endpoint(svc_name)
            if endpoint:
                accessible.append(svc_name)
                print(f"  âœ“ {svc_name}: {endpoint}")
            else:
                inaccessible.append(svc_name)
                print(f"  âœ— {svc_name}: NOT FOUND")

        result = {
            'required': len(required_services),
            'accessible': len(accessible),
            'inaccessible': inaccessible,
            'passed': len(inaccessible) == 0
        }

        return result

    def validate_persistent_storage(self) -> Dict[str, any]:
        """Validate PVCs are bound"""
        print("\nðŸ’¾ Infrastructure: Persistent Storage")

        pvcs = self.k8s.v1.list_namespaced_persistent_volume_claim(
            namespace=self.k8s.namespace
        )

        bound = []
        unbound = []

        for pvc in pvcs.items:
            if pvc.status.phase == "Bound":
                bound.append(pvc.metadata.name)
                print(f"  âœ“ {pvc.metadata.name}: Bound ({pvc.spec.resources.requests['storage']})")
            else:
                unbound.append(pvc.metadata.name)
                print(f"  âœ— {pvc.metadata.name}: {pvc.status.phase}")

        result = {
            'total': len(pvcs.items),
            'bound': len(bound),
            'unbound': unbound,
            'passed': len(unbound) == 0
        }

        return result

    def validate_celery_workers(self) -> Dict[str, any]:
        """Validate all required Celery workers are deployed and running"""
        print("\nðŸ‘· Infrastructure: Celery Workers")

        required_workers = {
            'default': 'celery queue',
            'priority': 'priority tasks',
            'download': 'data download tasks',
            'refresh': 'refresh tasks',
            'summary': 'summary tasks',
            'hcs': 'HCS tasks',
        }

        workers_status = {}
        missing = []
        not_ready = []

        for worker_type, description in required_workers.items():
            try:
                deployments = self.k8s.apps_v1.list_namespaced_deployment(
                    namespace=self.k8s.namespace,
                    label_selector=f"worker-queue={worker_type}"
                )

                if not deployments.items:
                    missing.append(f"{worker_type} ({description})")
                    workers_status[worker_type] = {'deployed': False, 'ready': False}
                    print(f"  âœ— {worker_type}: NOT DEPLOYED - {description}")
                else:
                    deployment = deployments.items[0]
                    ready_replicas = deployment.status.ready_replicas or 0
                    desired_replicas = deployment.spec.replicas
                    is_ready = ready_replicas >= desired_replicas

                    workers_status[worker_type] = {
                        'deployed': True,
                        'ready': is_ready,
                        'ready_replicas': ready_replicas,
                        'desired_replicas': desired_replicas
                    }

                    if is_ready:
                        print(f"  âœ“ {worker_type}: {ready_replicas}/{desired_replicas} ready - {description}")
                    else:
                        not_ready.append(f"{worker_type} ({ready_replicas}/{desired_replicas})")
                        print(f"  âš ï¸  {worker_type}: {ready_replicas}/{desired_replicas} ready - {description}")

            except Exception as e:
                missing.append(f"{worker_type} (error: {e})")
                workers_status[worker_type] = {'deployed': False, 'ready': False, 'error': str(e)}
                print(f"  âœ— {worker_type}: ERROR - {e}")

        result = {
            'required_count': len(required_workers),
            'deployed_count': sum(1 for w in workers_status.values() if w.get('deployed')),
            'ready_count': sum(1 for w in workers_status.values() if w.get('ready')),
            'missing': missing,
            'not_ready': not_ready,
            'workers': workers_status,
            'passed': len(missing) == 0 and len(not_ready) == 0
        }

        if result['passed']:
            print(f"  âœ… All {len(required_workers)} worker types deployed and ready")
        else:
            if missing:
                print(f"  âŒ Missing {len(missing)} worker types: {', '.join(missing)}")
            if not_ready:
                print(f"  âš ï¸  {len(not_ready)} workers not ready: {', '.join(not_ready)}")

        return result

    # ========================================================================
    # Integration Validation
    # ========================================================================

    def validate_database_connectivity(self) -> Dict[str, any]:
        """Validate database connections work"""
        print("\nðŸ”— Integration: Database Connectivity")

        tests = {
            'koku_db': False,
            'tables_exist': False,
            'can_query': False
        }

        try:
            # Test basic connection
            result = self.db.execute_query("SELECT version()", fetch_one=True)
            tests['koku_db'] = result is not None
            print("  âœ“ Koku DB connection")
        except Exception as e:
            print(f"  âœ— Koku DB connection: {e}")

        try:
            # Test critical tables exist
            result = self.db.execute_query("""
                SELECT COUNT(*) FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_name IN ('api_provider', 'api_customer', 'django_migrations')
            """, fetch_one=True)
            tests['tables_exist'] = result[0] == 3
            print(f"  {'âœ“' if tests['tables_exist'] else 'âœ—'} Critical tables exist")
        except Exception as e:
            print(f"  âœ— Table check: {e}")

        try:
            # Test can query data
            result = self.db.execute_query(
                "SELECT COUNT(*) FROM api_provider",
                fetch_one=True
            )
            tests['can_query'] = True
            print(f"  âœ“ Can query provider table ({result[0]} providers)")
        except Exception as e:
            print(f"  âœ— Query test: {e}")

        result = {
            'tests': tests,
            'passed': all(tests.values())
        }

        return result

    def validate_s3_integration(self, bucket: str = "koku-bucket") -> Dict[str, any]:
        """Validate S3/MinIO integration"""
        print("\nâ˜ï¸  Integration: S3 Storage")

        # Get S3 credentials from secret (try helm chart name first)
        storage_secret_name = f'{self.k8s.namespace}-storage-credentials'
        access_key = self.k8s.get_secret(storage_secret_name, 'access-key')
        secret_key = self.k8s.get_secret(storage_secret_name, 'secret-key')

        # Fallback to old secret name
        if not access_key or not secret_key:
            access_key = self.k8s.get_secret('koku-storage-credentials', 'access-key')
            secret_key = self.k8s.get_secret('koku-storage-credentials', 'secret-key')

        if not access_key or not secret_key:
            print("  âœ— S3 credentials not found")
            return {'passed': False, 'error': 'Credentials missing'}

        print("  âœ“ S3 credentials found")

        # Test S3 endpoint accessible from MASU pod
        masu_pod = self.k8s.get_pod_by_component('masu')
        if not masu_pod:
            print("  âœ— MASU pod not found")
            return {'passed': False, 'error': 'MASU pod not found'}

        try:
            output = self.k8s.python_exec(masu_pod, f"""
import boto3, os
s3 = boto3.client('s3',
    endpoint_url=os.environ.get('S3_ENDPOINT'),
    aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),
    aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),
    verify=False)
try:
    response = s3.list_buckets()
    print(f"BUCKETS={{len(response['Buckets'])}}")
    bucket_names = [b['Name'] for b in response['Buckets']]
    print(f"HAS_{bucket}={{'{bucket}' in bucket_names}}")
except Exception as e:
    print(f"ERROR={{e}}")
""")

            has_bucket = f"HAS_{bucket}=True" in output
            num_buckets = int(output.split("BUCKETS=")[1].split("\n")[0]) if "BUCKETS=" in output else 0

            print(f"  âœ“ S3 accessible ({num_buckets} buckets)")
            print(f"  {'âœ“' if has_bucket else 'âœ—'} Bucket '{bucket}' exists")

            return {
                'passed': has_bucket,
                'buckets': num_buckets,
                'target_bucket_exists': has_bucket
            }
        except Exception as e:
            print(f"  âœ— S3 test failed: {e}")
            return {'passed': False, 'error': str(e)}

    def validate_celery_integration(self) -> Dict[str, any]:
        """Validate Celery/Redis integration"""
        print("\nâš™ï¸  Integration: Celery Task Queue")

        masu_pod = self.k8s.get_pod_by_component('masu')
        if not masu_pod:
            return {'passed': False, 'error': 'MASU pod not found'}

        try:
            output = self.k8s.python_exec(masu_pod, """
import os, sys, django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'koku.settings')
sys.path.append('/opt/koku/koku')
django.setup()
from celery import Celery
from kombu import Connection

# Test Redis connection
redis_url = os.environ.get('REDIS_URL', 'redis://redis:6379/0')
try:
    conn = Connection(redis_url)
    conn.connect()
    print("REDIS_CONNECTED=True")
    conn.release()
except Exception as e:
    print(f"REDIS_ERROR={e}")

# Test Celery app
try:
    from masu.celery import celery as celery_app
    print(f"CELERY_TASKS={len(celery_app.tasks)}")
    print("CELERY_CONFIGURED=True")
except Exception as e:
    print(f"CELERY_ERROR={e}")
""")

            redis_ok = "REDIS_CONNECTED=True" in output
            celery_ok = "CELERY_CONFIGURED=True" in output
            num_tasks = 0
            if "CELERY_TASKS=" in output:
                num_tasks = int(output.split("CELERY_TASKS=")[1].split("\n")[0])

            print(f"  {'âœ“' if redis_ok else 'âœ—'} Redis connection")
            print(f"  {'âœ“' if celery_ok else 'âœ—'} Celery configuration")
            print(f"  âœ“ {num_tasks} tasks registered")

            return {
                'redis_connected': redis_ok,
                'celery_configured': celery_ok,
                'num_tasks': num_tasks,
                'passed': redis_ok and celery_ok and num_tasks > 10
            }
        except Exception as e:
            print(f"  âœ— Celery test failed: {e}")
            return {'passed': False, 'error': str(e)}

    # ========================================================================
    # Data Flow Validation
    # ========================================================================

    def validate_data_pipeline(self) -> Dict[str, any]:
        """Validate end-to-end data pipeline (PostgreSQL-based)"""
        print("\nðŸ”„ Data Flow: Pipeline Validation")

        stages = {
            's3_to_masu': False,
            'masu_to_postgres': False,
            'postgres_summary': False,
        }

        # Check S3 data exists
        # (Already validated in s3_integration)
        stages['s3_to_masu'] = True
        print("  âœ“ Stage 1: S3 â†’ MASU")

        # Check data in Postgres (manifests processed)
        try:
            manifest_count = self.db.get_manifest_count()
            stages['masu_to_postgres'] = manifest_count > 0
            print(f"  {'âœ“' if stages['masu_to_postgres'] else 'âœ—'} "
                  f"Stage 2: MASU â†’ Postgres ({manifest_count} manifests)")
        except:
            print("  âœ— Stage 2: MASU â†’ Postgres")

        # Check summary tables populated
        try:
            # Check if any summary data exists
            summary_exists = self.db.check_summary_tables()
            stages['postgres_summary'] = summary_exists
            print(f"  {'âœ“' if summary_exists else 'âœ—'} Stage 3: PostgreSQL Summary Tables")
        except:
            print("  âœ— Stage 3: PostgreSQL Summary Tables")

        result = {
            'stages': stages,
            'passed': all(stages.values())
        }

        return result

    # ========================================================================
    # Performance Validation
    # ========================================================================

    def validate_performance(self) -> Dict[str, any]:
        """Validate performance metrics"""
        print("\nâš¡ Performance: Response Times")

        # Check API response time
        api_pod = self.k8s.get_pod_by_component('koku-api')
        if not api_pod:
            return {'passed': False, 'error': 'API pod not found'}

        try:
            start = time.time()
            output = self.k8s.exec_in_pod(
                api_pod,
                ['curl', '-s', 'http://localhost:8000/api/cost-management/v1/status/']
            )
            api_response_time = time.time() - start

            print(f"  âœ“ API status endpoint: {api_response_time:.2f}s")

            # Check database query performance
            start = time.time()
            self.db.execute_query("SELECT COUNT(*) FROM api_provider")
            db_response_time = time.time() - start

            print(f"  âœ“ Database query: {db_response_time:.3f}s")

            result = {
                'api_response_time': api_response_time,
                'db_response_time': db_response_time,
                'passed': api_response_time < 5.0 and db_response_time < 1.0
            }

            if result['passed']:
                print("  âœ… Performance acceptable")
            else:
                print("  âš ï¸  Performance degraded")

            return result
        except Exception as e:
            print(f"  âœ— Performance test failed: {e}")
            return {'passed': False, 'error': str(e)}

    # ========================================================================
    # Operational Readiness
    # ========================================================================

    def validate_operational_readiness(self) -> Dict[str, any]:
        """Validate operational aspects"""
        print("\nðŸš€ Operational: Readiness Checks")

        checks = {
            'logs_accessible': False,
            'secrets_configured': False,
            'resource_limits': False,
            'monitoring_ready': False
        }

        # Check logs accessible
        try:
            api_pod = self.k8s.get_pod_by_component('koku-api')
            if api_pod:
                logs = self.k8s.v1.read_namespaced_pod_log(
                    api_pod,
                    self.k8s.namespace,
                    tail_lines=10
                )
                checks['logs_accessible'] = len(logs) > 0
                print(f"  {'âœ“' if checks['logs_accessible'] else 'âœ—'} Pod logs accessible")
        except Exception as e:
            print(f"  âœ— Pod logs: {e}")

        # Check secrets exist
        required_secrets = [
            'koku-db-credentials',
            'koku-storage-credentials',
        ]
        secrets_found = 0
        for secret_name in required_secrets:
            try:
                self.k8s.v1.read_namespaced_secret(secret_name, self.k8s.namespace)
                secrets_found += 1
            except:
                pass

        checks['secrets_configured'] = secrets_found == len(required_secrets)
        print(f"  {'âœ“' if checks['secrets_configured'] else 'âœ—'} "
              f"Secrets configured ({secrets_found}/{len(required_secrets)})")

        # Check resource limits set
        pods = self.k8s.get_pods()
        pods_with_limits = sum(
            1 for pod in pods
            if pod.spec.containers[0].resources.limits
        )
        checks['resource_limits'] = pods_with_limits > len(pods) * 0.5
        print(f"  {'âœ“' if checks['resource_limits'] else 'âœ—'} "
              f"Resource limits ({pods_with_limits}/{len(pods)} pods)")

        # Monitoring (placeholder - would integrate with Prometheus/Grafana)
        checks['monitoring_ready'] = True
        print("  âœ“ Monitoring configuration")

        result = {
            'checks': checks,
            'passed': all(checks.values())
        }

        return result

    # ========================================================================
    # Main Runner
    # ========================================================================

    def run_all_validations(self) -> Dict[str, any]:
        """Run all deployment validations

        Returns:
            Comprehensive validation results
        """
        print("\n" + "="*60)
        print("DEPLOYMENT VALIDATION SUITE")
        print("="*60)

        # Infrastructure
        self.results['infrastructure']['pod_health'] = self.validate_pod_health()
        self.results['infrastructure']['services'] = self.validate_services()
        self.results['infrastructure']['storage'] = self.validate_persistent_storage()
        self.results['infrastructure']['celery_workers'] = self.validate_celery_workers()

        # Integration
        self.results['integration']['database'] = self.validate_database_connectivity()
        self.results['integration']['s3'] = self.validate_s3_integration()
        self.results['integration']['celery'] = self.validate_celery_integration()

        # Data Flow
        self.results['data_flow']['pipeline'] = self.validate_data_pipeline()

        # Performance
        self.results['performance']['response_times'] = self.validate_performance()

        # Operational
        self.results['operational']['readiness'] = self.validate_operational_readiness()

        # Calculate overall score
        all_tests = []
        for category in self.results.values():
            for test_result in category.values():
                if isinstance(test_result, dict) and 'passed' in test_result:
                    all_tests.append(test_result['passed'])

        total = len(all_tests)
        passed = sum(all_tests)
        score = (passed / total * 100) if total > 0 else 0

        print("\n" + "="*60)
        print(f"DEPLOYMENT VALIDATION SCORE: {score:.0f}%")
        print(f"Passed: {passed}/{total} tests")
        print("="*60)

        # Determine overall pass/fail based on score threshold
        # Use 80% as passing threshold (less strict than deployment_ready 95%)
        passed_overall = score >= 80

        self.results['summary'] = {
            'total_tests': total,
            'passed_tests': passed,
            'score': score,
            'deployment_ready': score >= 95
        }

        # Add top-level 'passed' key for CLI status reporting
        self.results['passed'] = passed_overall
        self.results['skipped'] = False

        return self.results

